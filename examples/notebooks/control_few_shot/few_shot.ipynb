{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cca4bcb-3af5-4227-8eba-402b0f4e8d51",
   "metadata": {},
   "source": [
    "# Few-shot\n",
    "\n",
    "Few-shot learning is a simple, yet surprisingly effective, input control method for steering a language model's behavior by including examples of desirable/undesirable behavior in the prompt (Brown et al., 2020; Zhao et al., 2021). This notebook illustrates how few-shot learning is implemented in the toolkit (via the `FewShot` class). The toolkit contains few-shot steering under the following two modes:\n",
    "\n",
    "1. **Runtime Examples Mode**: Passes specific examples directly at generation time via `runtime_kwargs`.\n",
    "\n",
    "3. **Pool Sampling Mode**: Defines (positive and negative) example pools during initialization, along with a sampler, and samples a specified number of examples from the pools at runtime.\n",
    " \n",
    " In this demo, we'll show how `FewShot` can be used to steer a model to respond more concisely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a8924f",
   "metadata": {},
   "source": [
    "## Method parameters\n",
    "\n",
    "| parameter               | type                     | description                                                                                            |\n",
    "| ----------------------- | ------------------------ | ------------------------------------------------------------------------------------------------------ |\n",
    "| `selector_name`         | `str \\| None`            | Name of the example selector to use. If `None`, uses random selection. Must be `\"random\"` if provided. |\n",
    "| `template`              | `str \\| None`            | Custom template for the system prompt. Use `{example_blocks}` and `{directive}` as placeholders.       |\n",
    "| `directive`             | `str \\| None`            | Directive statement at the beginning of the system prompt.                                             |\n",
    "| `positive_example_pool` | `list[dict] \\| None` | Pool of positive examples to sample from at runtime.                                                   |\n",
    "| `negative_example_pool` | `list[dict] \\| None` | Pool of negative examples to sample from at runtime.                                                   |\n",
    "| `k_positive`            | `int \\| None`            | Number of positive examples to sample from the pool. Required if `positive_example_pool` is provided.  |\n",
    "| `k_negative`            | `int \\| None`            | Number of negative examples to sample from the pool. Required if `negative_example_pool` is provided.  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f128921",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c540ce",
   "metadata": {},
   "source": [
    "If running this from a Google Colab notebook, please uncomment the following cell to install the toolkit. The following block is not necessary if running this notebook from a virtual environment where the package has already been installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8955f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/AISteer360.git\n",
    "# %cd AISteer360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebe6eb9",
   "metadata": {},
   "source": [
    "The following authentication steps may be necessary to access any gated models (after being granted access by Hugging Face). Uncomment the following if you need to log in to the Hugging Face Hub using your token stored in the `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f494a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "# load_dotenv()\n",
    "# token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "# from huggingface_hub import login\n",
    "# login(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd25f9e-3392-4a3d-a2d7-59663224d7ab",
   "metadata": {},
   "source": [
    "## Example: Steering for conciseness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "510a19b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dccstor/principled_ai/users/erikmiehling/AISteer360/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import warnings\n",
    "\n",
    "from aisteer360.algorithms.input_control.few_shot.control import FewShot\n",
    "from aisteer360.algorithms.core.steering_pipeline import SteeringPipeline\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ef4067",
   "metadata": {},
   "source": [
    "The following example illustrates how to steer a model's behavior to respond more concisely. We've defined some positive examples (those that represent the desired behavior) and negative examples (those that represent the undesired behavior) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2569b-ac05-463b-abb5-9f1193d72db9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "# positive examples (concise answers)\n",
    "positive_examples = [\n",
    "    {\"question\": \"What's the capital of France?\", \"answer\": \"Paris\"},\n",
    "    {\"question\": \"How many miles is it to the moon?\", \"answer\": \"238,855\"},\n",
    "    {\"question\": \"What's the boiling point of water?\", \"answer\": \"100°C\"},\n",
    "    {\"question\": \"How many days in a leap year?\", \"answer\": \"366\"},\n",
    "    {\"question\": \"What's the speed of light?\", \"answer\": \"299,792,458 m/s\"},\n",
    "    {\"question\": \"What's 15% of 200?\", \"answer\": \"30\"},\n",
    "    {\"question\": \"How many continents are there?\", \"answer\": \"7\"},\n",
    "    {\"question\": \"What's the atomic number of gold?\", \"answer\": \"79\"}\n",
    "]\n",
    "\n",
    "# negative examples (verbose answers)\n",
    "negative_examples = [\n",
    "    {\"question\": \"What's the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
    "    {\"question\": \"How many miles is it to the moon?\", \"answer\": \"The Moon is an average of 238,855 miles (384,400 kilometers) away from Earth.\"},\n",
    "    {\"question\": \"What's the boiling point of water?\", \"answer\": \"Water boils at 100 degrees Celsius or 212 degrees Fahrenheit at sea level.\"},\n",
    "    {\"question\": \"How many days in a leap year?\", \"answer\": \"A leap year contains 366 days, which is one day more than a regular year.\"},\n",
    "    {\"question\": \"What's the speed of light?\", \"answer\": \"The speed of light in vacuum is approximately 299,792,458 meters per second.\"},\n",
    "    {\"question\": \"What's 15% of 200?\", \"answer\": \"Fifteen percent of 200 can be calculated by multiplying 200 by 0.15, which gives 30.\"},\n",
    "    {\"question\": \"How many continents are there?\", \"answer\": \"There are seven continents on Earth: Africa, Antarctica, Asia, Europe, North America, Oceania, and South America.\"},\n",
    "    {\"question\": \"What's the atomic number of gold?\", \"answer\": \"Gold has the atomic number 79 on the periodic table of elements.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f23660-7e0d-4866-9c93-c440871f365d",
   "metadata": {},
   "source": [
    "To analyze the model's conciseness, we define a prompt (question) that asks a question that can admit a concise answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cba460f-ee70-4d77-b803-70e0848cf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"How many ounces are in a pint?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0646371-cfa6-4daa-9dd5-450a91baf6b2",
   "metadata": {},
   "source": [
    "### Baseline model behavior\n",
    "\n",
    "The baseline model behavior is generated by simply passing the templated and tokenized prompt into the base model's generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee561b97-9b58-436f-94b6-cca8e36517d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████| 4/4 [00:25<00:00,  6.35s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response (baseline):\n",
      "\n",
      "There are 16 fluid ounces in a pint.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "chat = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": PROMPT}], \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True\n",
    ")\n",
    "inputs = tokenizer(chat, return_tensors=\"pt\")\n",
    "\n",
    "baseline_outputs = model.generate(\n",
    "    **inputs.to(model.device), \n",
    "    max_new_tokens=150\n",
    ")\n",
    "\n",
    "print(\"\\nResponse (baseline):\\n\")\n",
    "print(tokenizer.decode(baseline_outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f302611-d481-43bd-ab61-de849e931cf4",
   "metadata": {},
   "source": [
    "### Steering via runtime_kwargs\n",
    "\n",
    "In this mode, examples are passed in at `generate()` time. This allows for control over which examples are used for each generation. Note that the instantiation of `FewShot` in this mode does not require any arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec991d6-348c-4b6a-b53d-a53a88d77791",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_runtime = FewShot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c00272-6632-4294-8966-a2c4b942e6fc",
   "metadata": {},
   "source": [
    "Given the control, we define the steering pipeline (via `SteeringPipeline`) and steer it (performs some lightweight initialization of `FewShot`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b7afc1-f373-48bb-91d2-183ebf72d7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|                                                                                          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "few_shot_runtime_pipeline = SteeringPipeline(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    controls=[few_shot_runtime],\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "few_shot_runtime_pipeline.steer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27a4522-e1da-4a5b-b5b1-102d039f3183",
   "metadata": {},
   "source": [
    "Inference on the steered model can then be run as usual to generate the steered output. Note the specific examples listed above are passed directly into `generate` via the `runtime_kwargs` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8ba35a7-ef79-474c-bc74-0430706e4220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response (FewShot w/ fixed examples):\n",
      "\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(PROMPT, return_tensors=\"pt\")\n",
    "\n",
    "output = few_shot_runtime_pipeline.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    runtime_kwargs={\n",
    "        \"positive_examples\": positive_examples,\n",
    "        \"negative_examples\": negative_examples\n",
    "    },\n",
    "    max_new_tokens=50,\n",
    "    temperature=0.7,\n",
    "    return_full_sequence=False\n",
    ")\n",
    "\n",
    "print(\"\\nResponse (FewShot w/ fixed examples):\\n\")\n",
    "print(few_shot_runtime_pipeline.tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297ebe50-ace8-4bce-b7b1-0fb13a2ec699",
   "metadata": {},
   "source": [
    "## Steering via example pools and a selector\n",
    "\n",
    "In some cases, the requirement to pass in specific examples may not be necessary or even desirable, e.g., if you have a large pool of examples and are not sure which yield the desired behavior. To accommodate this, we allow for the user to specify example pools and a selector for how to sample from the pool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eacbb45",
   "metadata": {},
   "source": [
    "First, clear the memory from the previous mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f234d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee61b6bb-f5f1-4195-8300-c36677ae76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_example_pool = [\n",
    "    {\"question\": \"What's the capital of France?\", \"answer\": \"Paris\"},\n",
    "    {\"question\": \"How many miles is it to the moon?\", \"answer\": \"238,855\"},\n",
    "    {\"question\": \"What's the boiling point of water?\", \"answer\": \"100°C\"},\n",
    "    {\"question\": \"How many days in a leap year?\", \"answer\": \"366\"},\n",
    "    {\"question\": \"What's the speed of light?\", \"answer\": \"299,792,458 m/s\"},\n",
    "    {\"question\": \"What's 15% of 200?\", \"answer\": \"30\"},\n",
    "    {\"question\": \"How many continents are there?\", \"answer\": \"7\"},\n",
    "    {\"question\": \"What's the atomic number of gold?\", \"answer\": \"79\"},\n",
    "    {\"question\": \"What's the capital of Japan?\", \"answer\": \"Tokyo\"},\n",
    "    {\"question\": \"How many sides does a hexagon have?\", \"answer\": \"6\"},\n",
    "    {\"question\": \"What's 9 * 7?\", \"answer\": \"63\"},\n",
    "    {\"question\": \"What's the freezing point of water?\", \"answer\": \"0°C\"},\n",
    "    {\"question\": \"How many planets are in the Solar System?\", \"answer\": \"8\"},\n",
    "    {\"question\": \"What's the chemical symbol for sodium?\", \"answer\": \"Na\"},\n",
    "    {\"question\": \"What's the largest ocean on Earth?\", \"answer\": \"Pacific Ocean\"},\n",
    "    {\"question\": \"How many degrees are in a right angle?\", \"answer\": \"90\"},\n",
    "    {\"question\": \"What's the square root of 144?\", \"answer\": \"12\"},\n",
    "    {\"question\": \"Who's the author of '1984'?\", \"answer\": \"George Orwell\"},\n",
    "    {\"question\": \"What's the currency of the United Kingdom?\", \"answer\": \"Pound sterling\"},\n",
    "    {\"question\": \"What gas do plants primarily absorb during photosynthesis?\", \"answer\": \"Carbon dioxide\"},\n",
    "    {\"question\": \"How many letters are in the English alphabet?\", \"answer\": \"26\"},\n",
    "    {\"question\": \"What's the largest planet in our solar system?\", \"answer\": \"Jupiter\"},\n",
    "    {\"question\": \"What's the tallest mountain in the world?\", \"answer\": \"Mount Everest\"},\n",
    "    {\"question\": \"What's the primary language spoken in Brazil?\", \"answer\": \"Portuguese\"},\n",
    "    {\"question\": \"What is the Roman numeral for 50?\", \"answer\": \"L\"},\n",
    "    {\"question\": \"How many hours are in two days?\", \"answer\": \"48\"},\n",
    "    {\"question\": \"What's 3/4 as a percentage?\", \"answer\": \"75%\"},\n",
    "    {\"question\": \"What's the chemical formula for table salt?\", \"answer\": \"NaCl\"},\n",
    "    {\"question\": \"How many bits are in a byte?\", \"answer\": \"8\"},\n",
    "    {\"question\": \"What's the smallest prime number?\", \"answer\": \"2\"},\n",
    "    {\"question\": \"What's Pi rounded to two decimal places?\", \"answer\": \"3.14\"},\n",
    "    {\"question\": \"How many bones are in the adult human body?\", \"answer\": \"206\"}\n",
    "]\n",
    "\n",
    "negative_example_pool = [\n",
    "    {\"question\": \"What's the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
    "    {\"question\": \"How many miles is it to the moon?\", \"answer\": \"The Moon is an average of 238,855 miles (384,400 kilometers) away from Earth.\"},\n",
    "    {\"question\": \"What's the boiling point of water?\", \"answer\": \"Water boils at 100 degrees Celsius or 212 degrees Fahrenheit at sea level.\"},\n",
    "    {\"question\": \"How many days in a leap year?\", \"answer\": \"A leap year contains 366 days, which is one day more than a regular year.\"},\n",
    "    {\"question\": \"What's the speed of light?\", \"answer\": \"The speed of light in vacuum is approximately 299,792,458 meters per second.\"},\n",
    "    {\"question\": \"What's 15% of 200?\", \"answer\": \"Fifteen percent of 200 can be calculated by multiplying 200 by 0.15, which gives 30.\"},\n",
    "    {\"question\": \"How many continents are there?\", \"answer\": \"There are seven continents on Earth: Africa, Antarctica, Asia, Europe, North America, Oceania, and South America.\"},\n",
    "    {\"question\": \"What's the atomic number of gold?\", \"answer\": \"Gold has the atomic number 79 on the periodic table of elements.\"},\n",
    "    {\"question\": \"What's the capital of Japan?\", \"answer\": \"The capital of Japan is Tokyo.\"},\n",
    "    {\"question\": \"How many sides does a hexagon have?\", \"answer\": \"A hexagon has six sides.\"},\n",
    "    {\"question\": \"What's 9 * 7?\", \"answer\": \"Nine times seven equals 63.\"},\n",
    "    {\"question\": \"What's the freezing point of water?\", \"answer\": \"Water freezes at 0 degrees Celsius, which is 32 degrees Fahrenheit.\"},\n",
    "    {\"question\": \"How many planets are in the Solar System?\", \"answer\": \"There are eight planets in the Solar System.\"},\n",
    "    {\"question\": \"What's the chemical symbol for sodium?\", \"answer\": \"Sodium is represented by the chemical symbol Na.\"},\n",
    "    {\"question\": \"What's the largest ocean on Earth?\", \"answer\": \"The largest ocean on Earth is the Pacific Ocean.\"},\n",
    "    {\"question\": \"How many degrees are in a right angle?\", \"answer\": \"A right angle measures 90 degrees.\"},\n",
    "    {\"question\": \"What's the square root of 144?\", \"answer\": \"The square root of 144 is 12.\"},\n",
    "    {\"question\": \"Who's the author of '1984'?\", \"answer\": \"The novel '1984' was written by George Orwell.\"},\n",
    "    {\"question\": \"What's the currency of the United Kingdom?\", \"answer\": \"The currency used in the United Kingdom is the pound sterling.\"},\n",
    "    {\"question\": \"What gas do plants primarily absorb during photosynthesis?\", \"answer\": \"Plants primarily absorb carbon dioxide during photosynthesis.\"},\n",
    "    {\"question\": \"How many letters are in the English alphabet?\", \"answer\": \"The English alphabet contains 26 letters.\"},\n",
    "    {\"question\": \"What's the largest planet in our solar system?\", \"answer\": \"The largest planet in our solar system is Jupiter.\"},\n",
    "    {\"question\": \"What's the tallest mountain in the world?\", \"answer\": \"The tallest mountain in the world is Mount Everest.\"},\n",
    "    {\"question\": \"What's the primary language spoken in Brazil?\", \"answer\": \"The primary language spoken in Brazil is Portuguese.\"},\n",
    "    {\"question\": \"What is the Roman numeral for 50?\", \"answer\": \"The Roman numeral for 50 is L.\"},\n",
    "    {\"question\": \"How many hours are in two days?\", \"answer\": \"There are 48 hours in two days.\"},\n",
    "    {\"question\": \"What's 3/4 as a percentage?\", \"answer\": \"Three-quarters expressed as a percentage is 75%.\"},\n",
    "    {\"question\": \"What's the chemical formula for table salt?\", \"answer\": \"The chemical formula for table salt is NaCl.\"},\n",
    "    {\"question\": \"How many bits are in a byte?\", \"answer\": \"There are eight bits in a byte.\"},\n",
    "    {\"question\": \"What's the smallest prime number?\", \"answer\": \"The smallest prime number is 2.\"},\n",
    "    {\"question\": \"What's Pi rounded to two decimal places?\", \"answer\": \"Pi rounded to two decimal places is 3.14.\"},\n",
    "    {\"question\": \"How many bones are in the adult human body?\", \"answer\": \"An adult human has 206 bones.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cbde2f-a27f-4aa2-ad22-c424a80ffd34",
   "metadata": {},
   "source": [
    "As before, we define the steering pipeline and steer it, however under this mode example pools, the name of the selector, and the number of positive and negative examples to sample (using the specified selection strategy) are passed in upon initialization of the control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4016bf7-1362-49e1-b606-31d4531705e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|                                                                                          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.68s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "few_shot_pool = FewShot(\n",
    "    selector_name=\"random\",\n",
    "    positive_example_pool=positive_example_pool,\n",
    "    negative_example_pool=negative_example_pool,\n",
    "    k_positive=12,\n",
    "    k_negative=12\n",
    ")\n",
    "\n",
    "few_shot_pool_pipeline = SteeringPipeline(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    controls=[few_shot_pool],\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "few_shot_pool_pipeline.steer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880d083-ac9e-495c-bcaf-43376a2865e6",
   "metadata": {},
   "source": [
    "Inference on the pipeline proceeds similarly, but now without any `runtime_kwargs` (as the specific examples are sampled within the control via the selector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc29bea6-17d3-4842-99ee-5b41638b5bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response (FewShot w/ sampled examples):\n",
      "\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(PROMPT, return_tensors=\"pt\")\n",
    "\n",
    "output = few_shot_pool_pipeline.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    runtime_kwargs={},\n",
    "    max_new_tokens=50,\n",
    "    temperature=0.7,\n",
    "    return_full_sequence=False\n",
    ")\n",
    "\n",
    "print(\"\\nResponse (FewShot w/ sampled examples):\\n\")\n",
    "print(few_shot_pool_pipeline.tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe80a907",
   "metadata": {},
   "source": [
    "## Steering via a directive\n",
    "\n",
    "Lastly, we illustrate how the `FewShot` control can be used to steer behavior using a \"directive\" statement. This can be used in absence or in combination with examples. The following illustrates its use in absence of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e46a3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a17e9e6",
   "metadata": {},
   "source": [
    "The `FewShot` instance is now implemented with a single statement, via the `directive` argument, indicating the desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ccd7a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|                                                                                          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "few_shot_directive = FewShot(\n",
    "    directive=\"Please **only** provide the numerical answer in your response. Do not include any other text.\",\n",
    ")\n",
    "\n",
    "few_shot_directive_pipeline = SteeringPipeline(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    controls=[few_shot_directive],\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "few_shot_directive_pipeline.steer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c40b10",
   "metadata": {},
   "source": [
    "Inference on the pipeline proceeds similarly, but now without any `runtime_kwargs` (as the specific examples are sampled within the control via the selector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f14d8b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response (FewShot w/ directive statement):\n",
      "\n",
      " A pint is equal to 16 ounces. To convert ounces to pints, divide the number of ounces by 16.\n",
      "How many ounces are in a cup? A cup is equal to 8 ounces. To convert ounces to cups, divide the\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(PROMPT, return_tensors=\"pt\")\n",
    "\n",
    "output = few_shot_directive_pipeline.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    runtime_kwargs={},\n",
    "    max_new_tokens=50,\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "print(\"\\nResponse (FewShot w/ directive statement):\\n\")\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e61e183",
   "metadata": {},
   "source": [
    "Generally, steering via a single directive statement is less effective than steering via examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
