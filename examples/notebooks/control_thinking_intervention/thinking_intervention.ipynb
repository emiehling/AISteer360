{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2715964",
   "metadata": {},
   "source": [
    "<img src=\"./thinking_intervention.png\" alt=\"ThinkingIntervention method\" width=\"1000\"/>\n",
    "\n",
    "(Image from Wu et al., 2025)\n",
    "\n",
    "# Thinking Intervention\n",
    "\n",
    "**Paper**: [Effectively Controlling Reasoning Models through Thinking Intervention](https://arxiv.org/pdf/2503.24370)\n",
    "\n",
    "**Authors**: Tong Wu, Chong Xiang, Jiachen Wang, Edward Suh, Prateek Mittal\n",
    "\n",
    "Thinking Intervention is a steering method that guides an LLM's reasoning processes via the insertion of specific thinking tokens or phrases. \n",
    "\n",
    "As illustrated in the original paper, the inclusion of task-specific reasoning tokens in the model's reasoning process can boost their performance on different tasks.\n",
    "\n",
    "In this demo, we present an example from the paper on instructing the model to follow specific formatting instructions (i.e., generate an itinerary without using any commas)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e46336",
   "metadata": {},
   "source": [
    "## Method Parameters\n",
    "| parameter      | type                    | description                                                                                         |\n",
    "| -------------- | ----------------------- | --------------------------------------------------------------------------------------------------- |\n",
    "| `intervention` | `Callable[[str, dict]]` | A callable that takes `(prompt: str, state: dict)`. Must be callable; otherwise raises `TypeError`. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce46163",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd909c",
   "metadata": {},
   "source": [
    "If running this from a Google Colab notebook, please uncomment the following cell to install the toolkit. The following block is not necessary if running this notebook from a virtual environment where the package has already been installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab06d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/AISteer360.git\n",
    "# %cd AISteer360"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dad7ac",
   "metadata": {},
   "source": [
    "The following authentication steps may be necessary to access any gated models (after being granted access by Hugging Face). Uncomment the following if you need to log in to the Hugging Face Hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-dotenv\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "# load_dotenv()\n",
    "# token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "# from huggingface_hub import login\n",
    "# login(token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2e3ca",
   "metadata": {},
   "source": [
    "## Example: Steering for formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91bd5026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from aisteer360.algorithms.output_control.thinking_intervention.control import ThinkingIntervention\n",
    "from aisteer360.algorithms.core.steering_pipeline import SteeringPipeline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-1.5B-Instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc2811",
   "metadata": {},
   "source": [
    "\n",
    "We specify the `<think>` and `</think>` tags in the prompt to encourage the model to reason (as described in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f0c562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "I would like to come up with a 3-day itinerary to Paris without using any commas. Use the <think> and </think> tags to reason first before responding with the final itinerary.<|im_end|>\n",
      "<|im_start|>assistant\n",
      " <think>\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "prompt = \"I would like to come up with a 3-day itinerary to Paris without using any commas. Use the <think> and </think> tags to reason first before responding with the final itinerary.\"\n",
    "chat = tokenizer.apply_chat_template(\n",
    "    [{\"role\": \"user\", \"content\": prompt}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "chat = chat + \" <think>\"\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd22b4",
   "metadata": {},
   "source": [
    "The baseline (unsteered) response is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebb59270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response (baseline):\n",
      "\n",
      "Planning a 3-day itinerary for Paris involves selecting key attractions that offer a comprehensive overview of the city's history, culture, art, and cuisine. Here\u2019s how we can structure it:</think>\n",
      "\n",
      "1. **Morning: Montmartre & Sacr\u00e9-C\u0153ur Basilica**\n",
      "   - Start your day at the picturesque streets of Montmartre, known for its artists' studios and winding cobblestone lanes.\n",
      "   - Visit the iconic Sacr\u00e9-C\u0153ur Basilica, one of the most recognizable landmarks in Paris.\n",
      "\n",
      "2. **Afternoon: Louvre Museum & Place des Vosges**\n",
      "   - After exploring Montmartre, head to the Louvre Museum, home to some of the world's greatest works of art.\n",
      "   - Take a leisurely stroll through the beautiful Place des Vosges, a square surrounded by historic buildings.\n",
      "\n",
      "3. **Evening: Notre-Dame Cathedral & Eiffel Tower**\n",
      "   - End your day with a visit to Notre-Dame Cathedral, an architectural masterpiece and a symbol of Parisian Gothic architecture.\n",
      "   - Conclude your trip with a panoramic view of the city from the top of the Eiffel Tower.\n",
      "\n",
      "This itinerary balances historical significance, cultural richness, and natural beauty, providing a well-rounded experience of Paris.\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(chat ,return_tensors=\"pt\").to(model.device)\n",
    "baseline_outputs = model.generate(\n",
    "    **inputs, \n",
    "    do_sample=False,\n",
    "    max_new_tokens=300,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "print(\"\\nResponse (baseline):\\n\")\n",
    "print(tokenizer.decode(baseline_outputs[0][len(inputs['input_ids'][0]):], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71348746",
   "metadata": {},
   "source": [
    "Notice that the model has used multiple commas in its response despite the instruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f2655",
   "metadata": {},
   "source": [
    "Let's now apply the `ThinkingIntervention` control. We first design an intervention function to add a task-specific intervention to the reasoning process. The paper claims that applying these interventions at the beginning of the reasoning process yields the best performance. We create a simple intervention (derived from the paper), to prompt the model to avoid using commas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67cd3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itinerary_intervention(prompt: str, params: dict) -> str:\n",
    "        intervention = \" I should ensure that the answer does not use any commas. \"\n",
    "        return prompt + intervention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f1e360",
   "metadata": {},
   "source": [
    "We pass this to the `ThinkingIntervention` control, define the steering pipeline, and steer it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ec14f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "thinking_intervention = ThinkingIntervention(\n",
    "   intervention=itinerary_intervention \n",
    ")\n",
    "thinking_intervention_pipeline = SteeringPipeline(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    controls=[thinking_intervention],\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "thinking_intervention_pipeline.steer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e91be43",
   "metadata": {},
   "source": [
    "The corresponding (steered) response is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14fd1059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response (ThinkingIntervention):\n",
      "\n",
      "Paris Itinerary:\n",
      "- Morning: Start at the Louvre Museum\n",
      "- Afternoon: Visit the Eiffel Tower\n",
      "- Evening: Dinner at Le Jules Verne restaurant\n",
      "- Late Afternoon: Stroll through Montmartre and visit Sacr\u00e9-C\u0153ur Basilica\n",
      "- Night: End your trip at the Mus\u00e9e d'Orsay\n",
      "\n",
      "This itinerary ensures you see some of the most iconic landmarks while avoiding commas. Enjoy exploring Paris!\n"
     ]
    }
   ],
   "source": [
    "output = thinking_intervention_pipeline.generate(\n",
    "    input_ids=inputs['input_ids'],\n",
    "    max_new_tokens=300,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "print(\"\\nResponse (ThinkingIntervention):\\n\")\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3bba1",
   "metadata": {},
   "source": [
    "The output no longer contains any commas, as instructed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550caa69",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
