{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Activation Addition (ActAdd)\n",
    "\n",
    "**Paper**: [Steering Language Models With Activation Engineering](https://arxiv.org/abs/2308.10248)\n",
    "\n",
    "**Authors**: Alexander Matt Turner, Lisa Thiergart, Gavin Leech, David Udell, Juan J. Vazquez, Ulisse Mini, Monte MacDiarmid\n",
    "\n",
    "Activation Addition (ActAdd) is a state control method that steers model behavior by computing a positional steering vector from a single pair of short prompts and injecting it during the initial forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Method Parameters\n",
    "\n",
    "| parameter              | type                | description                                                                                   |\n",
    "| ---------------------- | ------------------- | --------------------------------------------------------------------------------------------- |\n",
    "| `positive_prompt`      | `str`               | Prompt representing the desired direction (e.g., `\"Love\"`)                                    |\n",
    "| `negative_prompt`      | `str`               | Prompt representing the opposite direction (e.g., `\"Hate\"`)                                   |\n",
    "| `steering_vector`      | `SteeringVector`    | Pre-computed steering vector (alternative to prompts)                                         |\n",
    "| `layer_id`             | `int`               | Layer to inject at. If `None`, defaults to ~20% depth                                         |\n",
    "| `multiplier`           | `float`             | Scaling coefficient (called `c` in the paper). Typical values range from 1 to 15              |\n",
    "| `alignment`            | `int`               | Token position at which to begin injecting (called `a` in the paper). Default: 1              |\n",
    "| `normalize_vector`     | `bool`              | If `True`, L2-normalize each position's direction vector before applying                      |\n",
    "| `use_norm_preservation`| `bool`              | If `True`, wrap the transform in `NormPreservingTransform` to prevent distribution shift      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "If running this from a Google Colab notebook, please uncomment the following cell to install the toolkit. The following block is not necessary if running this notebook from a virtual environment where the package has already been installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/IBM/AISteer360.git\n",
    "# %cd AISteer360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aisteer360.algorithms.state_control.act_add.control import ActAdd\n",
    "from aisteer360.algorithms.core.steering_pipeline import SteeringPipeline\n",
    "\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "For this demonstration, we use GPT-2-XL (1.5B parameters, 48 layers), the same model used in the original paper. This allows us to use the paper's recommended hyperparameters directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gpt2-xl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "We define a small set of test prompts to observe steering effects. These open-ended prompts allow us to see how the model's completions shift under different steering configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prompts = [\n",
    "    \"I think you're\",\n",
    "    \"My favorite thing about life is\",\n",
    "    \"I went up to my friend and said\",\n",
    "    \"To be honest, I think\",\n",
    "    \"The weather today is\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Baseline Model Behavior\n",
    "\n",
    "Before applying any steering, we observe the baseline model's completions to establish a reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "device = model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline completions:\n",
      "\n",
      "Prompt: I think you're\n",
      "Response: I think you're right, but I'm not sure how to make it work. I'm not sure how to make it work.\n",
      "\n",
      "I'm not sure how\n",
      "\n",
      "Prompt: My favorite thing about life is\n",
      "Response: My favorite thing about life is that it's never the same twice. I'm always learning and growing, and I'm always learning about myself. I'm always learning about the world\n",
      "\n",
      "Prompt: I went up to my friend and said\n",
      "Response: I went up to my friend and said, 'I'm going to be a lawyer.' He said, 'You're going to be a lawyer and you're going to be a lawyer and\n",
      "\n",
      "Prompt: To be honest, I think\n",
      "Response: To be honest, I think it's a good idea. I think it's a good idea to have a lot of people in the room. I think it's a good idea\n",
      "\n",
      "Prompt: The weather today is\n",
      "Response: The weather today is perfect for a walk in the woods. I'm going to walk in the woods with my dog, and we're going to have a great time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_params = {\n",
    "    \"max_new_tokens\": 30,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.9,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}\n",
    "\n",
    "# batch tokenize with left padding for generation\n",
    "tokenizer.padding_side = \"left\"\n",
    "batch_inputs = tokenizer(test_prompts, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "# batch generate\n",
    "with torch.no_grad():\n",
    "    output_ids = model.generate(**batch_inputs, **gen_params)\n",
    "\n",
    "# decode, stripping the prompt portion\n",
    "baseline_responses = []\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    response = tokenizer.decode(output_ids[i], skip_special_tokens=True)\n",
    "    baseline_responses.append(response)\n",
    "\n",
    "print(\"Baseline completions:\\n\")\n",
    "for prompt, response in zip(test_prompts, baseline_responses):\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Sentiment Steering\n",
    "\n",
    "The first example demonstrates sentiment steering using a simple `\"Love\"` vs `\"Hate\"` prompt pair (this example is from the paper and shows how a single word contrast can shift completions). The `alignment=1` parameter specifies that the steering vector should be injected starting at token position 1 (after the BOS token); this aligns the steering effect with the beginning of the user's prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_add_sentiment = ActAdd(\n",
    "    positive_prompt=\"Love\",\n",
    "    negative_prompt=\"Hate\",\n",
    "    layer_id=6,\n",
    "    multiplier=12.0,\n",
    "    alignment=1,\n",
    ")\n",
    "\n",
    "sentiment_pipeline = SteeringPipeline(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    controls=[act_add_sentiment],\n",
    ")\n",
    "sentiment_pipeline.steer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment-steered completions (Love - Hate, multiplier=15.0):\n",
      "\n",
      "Prompt: I think you're\n",
      "Response:  right. I'm not sure what the right answer is, but I'm going to try to figure it out.\n",
      "\n",
      "I'm not sure what\n",
      "\n",
      "Prompt: My favorite thing about life is\n",
      "Response:  that it's never over.\n",
      "\n",
      "I've been writing for a while now, and I'm still not done. I'm not sure what I\n",
      "\n",
      "Prompt: I went up to my friend and said\n",
      "Response:  goodbye to my friends and my family\n",
      "\n",
      "Love and Happiness\n",
      "I love and Happiness\n",
      "\n",
      "I love and Happiness\n",
      "\n",
      "I love and Happiness\n",
      "\n",
      "\n",
      "Prompt: To be honest, I think\n",
      "Response:  the first thing that comes to mind is the \"T\" in \"T.A.T.U.M.S.\".\n",
      "\n",
      "I\n",
      "\n",
      "Prompt: The weather today is\n",
      "Response:  perfect for a picnic. We are going to have a picnic in the park. We will be in the park for about an hour. We will be\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# batch tokenize with left padding\n",
    "tokenizer.padding_side = \"left\"\n",
    "batch_inputs = tokenizer(test_prompts, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# batch generate with steering\n",
    "output_ids = sentiment_pipeline.generate(\n",
    "    input_ids=batch_inputs.input_ids,\n",
    "    attention_mask=batch_inputs.attention_mask,\n",
    "    **gen_params,\n",
    ")\n",
    "\n",
    "sentiment_responses = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "print(\"Sentiment-steered completions (Love - Hate, multiplier=15.0):\\n\")\n",
    "for prompt, response in zip(test_prompts, sentiment_responses):\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    print(f\"Response: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### Comparing baseline vs. steered responses\n",
    "\n",
    "The table below shows the baseline and steered completions side by side. The sentiment steering shifts completions toward more positive emotional content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| prompt               | baseline                                 | steered (Love - Hate)                    |\n",
      "+======================+==========================================+==========================================+\n",
      "| I think you're       | I think you're right, but I'm not sure   | right. I'm not sure what the right       |\n",
      "|                      | how to make it work. I'm not sure how to | answer is, but I'm going to try to       |\n",
      "|                      | make it work.  I'm not sure how          | figure it out.  I'm not sure what        |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| My favorite thing    | My favorite thing about life is that     | that it's never over.  I've been         |\n",
      "| about life is        | it's never the same twice. I'm always    | writing for a while now, and I'm still   |\n",
      "|                      | learning and growing, and I'm always     | not done. I'm not sure what I            |\n",
      "|                      | learning about myself. I'm always        |                                          |\n",
      "|                      | learning about the world                 |                                          |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| I went up to my      | I went up to my friend and said, 'I'm    | goodbye to my friends and my family      |\n",
      "| friend and said      | going to be a lawyer.' He said, 'You're  | Love and Happiness I love and Happiness  |\n",
      "|                      | going to be a lawyer and you're going to | I love and Happiness  I love and         |\n",
      "|                      | be a lawyer and                          | Happiness                                |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| To be honest, I      | To be honest, I think it's a good idea.  | the first thing that comes to mind is    |\n",
      "| think                | I think it's a good idea to have a lot   | the \"T\" in \"T.A.T.U.M.S.\".  I            |\n",
      "|                      | of people in the room. I think it's a    |                                          |\n",
      "|                      | good idea                                |                                          |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| The weather today is | The weather today is perfect for a walk  | perfect for a picnic. We are going to    |\n",
      "|                      | in the woods. I'm going to walk in the   | have a picnic in the park. We will be in |\n",
      "|                      | woods with my dog, and we're going to    | the park for about an hour. We will be   |\n",
      "|                      | have a great time.                       |                                          |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "import textwrap\n",
    "\n",
    "def wrap(text, width=50):\n",
    "    return '\\n'.join(textwrap.wrap(text, width=width))\n",
    "\n",
    "table_data = []\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    table_data.append([\n",
    "        wrap(prompt, 20),\n",
    "        wrap(baseline_responses[i], 40),\n",
    "        wrap(sentiment_responses[i], 40),\n",
    "    ])\n",
    "\n",
    "print(tabulate(\n",
    "    table_data,\n",
    "    headers=[\"prompt\", \"baseline\", \"steered (Love - Hate)\"],\n",
    "    tablefmt=\"grid\",\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## Topic Steering\n",
    "\n",
    "ActAdd can also steer models toward specific topics. Here we use the wedding example inspired from the paper where contrasting prompts related to weddings are injected at specific layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_add_topic = ActAdd(\n",
    "    positive_prompt=\"always talking about weddings\",\n",
    "    negative_prompt=\"not always talking about weddings\",\n",
    "    layer_id=15,\n",
    "    multiplier=1.2,\n",
    "    alignment=1,\n",
    ")\n",
    "\n",
    "topic_pipeline = SteeringPipeline(\n",
    "    model_name_or_path=MODEL_NAME,\n",
    "    controls=[act_add_topic],\n",
    ")\n",
    "topic_pipeline.steer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| prompt               | baseline                                 | steered (weddings)                       |\n",
      "+======================+==========================================+==========================================+\n",
      "| I think you're       | I think you're right, but I'm not sure   | right. I'm not sure I can do it. I'm     |\n",
      "|                      | how to make it work. I'm not sure how to | not sure I can do it. I'm not sure I can |\n",
      "|                      | make it work.  I'm not sure how          | do it.                                   |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| My favorite thing    | My favorite thing about life is that     | that it's never the same twice.  I'm     |\n",
      "| about life is        | it's never the same twice. I'm always    | not sure what I'm going to do with my    |\n",
      "|                      | learning and growing, and I'm always     | life. I'm not sure what I                |\n",
      "|                      | learning about myself. I'm always        |                                          |\n",
      "|                      | learning about the world                 |                                          |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| I went up to my      | I went up to my friend and said, 'I'm    | , 'I'm sorry, I'm sorry, I'm sorry.' I   |\n",
      "| friend and said      | going to be a lawyer.' He said, 'You're  | was very sorry. I was very sorry. I was  |\n",
      "|                      | going to be a lawyer and you're going to | very sorry. I                            |\n",
      "|                      | be a lawyer and                          |                                          |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| To be honest, I      | To be honest, I think it's a good idea.  | the best way to do it is to have a lot   |\n",
      "| think                | I think it's a good idea to have a lot   | of people in the room, and then you can  |\n",
      "|                      | of people in the room. I think it's a    | have a lot of people in the room and     |\n",
      "|                      | good idea                                |                                          |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n",
      "| The weather today is | The weather today is perfect for a walk  | a little different. The sun is shining,  |\n",
      "|                      | in the woods. I'm going to walk in the   | the sky is blue, and the temperature is  |\n",
      "|                      | woods with my dog, and we're going to    | a little warmer.  The weather is a       |\n",
      "|                      | have a great time.                       | little different                         |\n",
      "+----------------------+------------------------------------------+------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "tokenizer.padding_side = \"left\"\n",
    "batch_inputs = tokenizer(test_prompts, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output_ids = topic_pipeline.generate(\n",
    "    input_ids=batch_inputs.input_ids,\n",
    "    attention_mask=batch_inputs.attention_mask,\n",
    "    **gen_params,\n",
    ")\n",
    "\n",
    "topic_responses = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "\n",
    "# side-by-side comparison\n",
    "table_data = []\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    table_data.append([\n",
    "        wrap(prompt, 20),\n",
    "        wrap(baseline_responses[i], 40),\n",
    "        wrap(topic_responses[i], 40),\n",
    "    ])\n",
    "\n",
    "print(tabulate(\n",
    "    table_data,\n",
    "    headers=[\"prompt\", \"baseline\", \"steered (weddings)\"],\n",
    "    tablefmt=\"grid\",\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-31",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated Activation Addition (ActAdd) for lightweight behavior steering:\n",
    "\n",
    "1. ActAdd computes a positional steering vector from just two short prompts, enabling rapid experimentation.\n",
    "2. The sentiment example showed how a simple `\"Love\"` vs `\"Hate\"` contrast shifts emotional tone.\n",
    "3. The topic example demonstrated steering toward specific content regardless of the input prompt.\n",
    "\n",
    "ActAdd trades off statistical robustness (using more than a single prompt pair) for speed and simplicity (a single pair suffices), say compared to contrastive activation addition (CAA). However, as shown by the above examples, it can be an effective method for steering toward clear, targeted behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
